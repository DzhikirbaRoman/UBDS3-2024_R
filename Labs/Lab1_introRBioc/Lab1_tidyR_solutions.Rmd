---
title: "Introduction to data structure and filtering"
author: "adapted from Julia Rühle"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    #theme: "cosmo"
    theme: "cerulean"
    #highlight: github  
    df_print: paged
    number_sections: yes
    toc: yes
    #code_folding: hide
    toc_depth: 4
    toc_float:
      collapsed: false
    highlight: tango
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 


```

# Getting started 

First, we install and load all the packages that we need for this tutorial.

```{r loading packages, include=TRUE, eval=TRUE, results='hide'}
pkgs_needed = c("tidyverse","dplyr","ggplot2","patchwork","DESeq2")
letsinstall = setdiff(pkgs_needed, installed.packages()) 
if (length(letsinstall) > 0) {
  for (pkg in letsinstall) {
    BiocManager::install(pkg, dependencies = TRUE)
  }
}

library(ggplot2)
library(dplyr)
library(tidyverse)
library(DESeq2)
library(patchwork)
```

# Exploring the Data Set & Cohort 

## Import data 

This tutorial uses data from: 

> Grant, R.A., Morales-Nebreda, L., Markov, N.S. et al. Circuits between infected macrophages and T cells in SARS-CoV-2 pneumonia. Nature 590, 635–641 (2021). https://doi.org/10.1038/s41586-020-03148-w

In the first part of this tutorial, we will read in and manipulate the data, using the tidyverse package. Let's start by reading in the bulk **RNA count data** using the function `read_csv()`{.R} from the tidyverse package and save it as a variable named *counts*. Use the same function to read in the corresponding **metadata** and name this variable *meta*. If you are unsure how to use the `read_csv()`{.R} function, you can type `?read_csv`{.R} into the console to get a detailed documentation of this function. Later, you will see why we are using the tidyverse package rather than the base R functions. 

The data are stored in a zip file. Please download the .zip file and unpack the .zip file via right click (extract all). After extracting the files you should have two files in your folder. 

- Count Data
- Meta Data

Now, set your working directory to the path of the folder that contains the count and the meta data. You can use the function `setwd()` and paste the path to your `data` folder that you just opened. (You don't know where it is? You can check the path using the terminal). 

```{r read in data, include=TRUE, eval=TRUE}

counts <- read_csv("./data/bulk_RNA_counts.csv")
meta <- read_csv("./data/bulk_RNA_metadata.csv")

```

## Structure of count and meta data

> **Hands-on:** 
>
* What does the abbreviation ENSG stand for? 
* How many genes does your count data have? 
* How many samples does your count data have? 
* Have a look at the meta data, what information do you have about the patients? 
* Whats the type of your data frame? How is it different from a dataframe read in using the base R `read.csv()`{.R} function?

**Solutions:**
```{r sol 1 , include=TRUE}

# What does the abbreviation ENSG stand for? 
# It stands for Ensembl Gene ID. Ensembl is a genome browser for vertebrate genomes. There is different genome browsers, so in some cases you will find different names for the same genes. 

# How many genes does your count data have? 
# This is the number of the rows in your count data 
nrow(counts)

# How many samples does your count data have? 
ncol(counts)

# Have a look at the meta data, what information do you have about the patients? 
# All of the patient information can be found in the columns of the meta data. 
meta

# Whats the type of your data frame? How is it different from a data frame read in using the base R `read.csv()`{.R} function?
# If you read in the data using the read_csv() function, this will create a tibble. Tibble is the data type we will need to apply the tidyverse package (which you will see later). For now, if you output the tibble compared to a data frame, not the whole table gets printed in the console and you´ll find some additional information about the data like the dimensions. 

```


Now, that we understand what kind of information we find in the columns and rows of the data provided, we can go ahead and explore the data. In order to make the right conclusions and not introduce any biases when we perform downstream analyses, we want to gather some basic information about the patients who participated in the study. 

> **Hands-on:** 
>
* What are the types of disease the patients were diagnosed with? 
* What are the proportions of women and men in this cohort? Count the number of samples per sex.
* Whats the minimum, maximum, and average age of the patients in this data set? 
* Of how many patients do we have single-cell RNA seq data from?

**Solutions:**
```{r sol2 , include=TRUE, eval = TRUE}

# What are the types of disease the patients were diagnosed with?
unique(meta$diagnosis)

# What are the proportions of women and men in this cohort? Count the number of samples per sex.
table(meta$sex)

# Whats the minimum, maximum, and average age of the patients in this data set? 
mean(meta$age)

# Of how many patients do we have single-cell RNA seq data from?
sum(!is.na(meta$scRNAseq_id))

```

## Describe your Cohort: Manipulating and analysing data with tidyverse

To be able to compute simple summary statistics on our data, we need to reshape and subset our data. Sometimes bracket subsetting (as it is done using base R functions) can be laborious and the code can become very difficult to read. 

The **tidyverse** package helps us to overcome these problems. This package includes of a variety of packages that are very useful and common in data analysis. If you want to read more, here you can find the [tidyverse vignette](https://www.tidyverse.org/packages/).  

One of these included packages is **dplyr**, and we are now going to learn some of the most common functions.

> Some very useful **dplyr** functions: 
>
 * Subsetting columns: `select()`{.R}
 * Subsetting Rows on Conditions:  `filter()`{.R}
 * Adding columns: `mutate()`{.R}
 * Compute Summary Statistics on subgroups of your data: `group_by()`{.R} & `summarise()`{.R} 
 

Let's have a look at some examples and how we can apply these dplyr functions to make our life easier. 

### Select columns and Filter rows 

**Selecting Columns:** 

```{r, include=TRUE, eval = FALSE}

#How do you select columns using bracket-subsetting?
# We can either do: 
meta[,c("sex", "diagnosis")]

#or
meta[,c(4,5)]

#Using tidyverse's select() function it works like the following
select(meta, diagnosis, sex)

#we can also do this: 
#this command selects every column except for the superinfection column 
select(meta, -superinfection) 

```

**Filtering Rows:** 

```{r, include = TRUE, eval = FALSE}

#How did you select rows before? 
meta[meta$diagnosis == "COVID-19", ]

#How does this work using tidyverse? 
filter(meta, diagnosis == "COVID-19")

#we can also select based on multiple criteria 
filter(meta, diagnosis == "COVID-19" & age > 60)

```

**Select and Filter at the same time:** \

For this, the **pipe symbol %>%** (shortcut: Cmd+Shift+m) comes in very handy.

```{r , eval = FALSE}
#coupling the two with bracket subsetting: 
meta[meta$diagnosis == "COVID-19" & meta$age > 60, c("sex", "diagnosis")] # :( this code is not very nice to read

#tidyverse:
meta %>%
  filter(diagnosis == "COVID-19" & age > 60) %>%  
  select(diagnosis, sex)

#Why does this chunk of code not work? 
meta %>% 
  select(diagnosis, sex) %>%  
  filter(diagnosis == "COVID-19" & age > 60)

```

### Add Columns 

In many cases, you want to create new columns using the values of existing columns. For this we are using the `mutate()`{.R} function. For example, you prefer to have even numbers for the age of the patients. So you want to round the existing ones, and create a new column with these.

```{r, eval = FALSE}
meta %>% 
  mutate(rounded_age = round(age))

```

### Summary Statistics 

In many data analysis tasks, we want to split the data into groups and apply the same analysis to each group and last, combine the results in a summarized table or plot. For this, we can use the `group_by()`{.R} and `summarise()`{.R} functions.

For example, in our case we are not particularly interested in the average age of the whole patient cohort. We could be more interested in the average age across the four different groups of diagnosis. This we can do in the following way: 

```{r, eval= FALSE}

meta %>% 
  group_by(diagnosis) %>% 
  dplyr::summarise(average_age = mean(age))

# Grouping can be also used to count occurrences 
# Here we are counting the number of patients across the different groups of diagnosis
meta %>% 
  group_by(diagnosis) %>% 
  dplyr::summarise(no_of_patients = n()) 

```


> **Hands-on:** 
>
* Can you extract all samples (rows) with covid patients?
* Can you extract all samples (rows) with covid patients that suffered from a super infection?
* How many samples do we have of patients with "Other Pnemumonia" that are younger than 50?
* What is the average "days from first intubation" for the covid patients compared to the average "days from first intubation" for the other groups of non-healthy patients?
* 

**Solutions**
```{r sol 3, eval= FALSE}

# Can you extract all samples (rows) with Covid patients?
meta %>% filter(diagnosis == "COVID-19")

#Can you extract all samples with Covid patients that suffered from a superinfection?
meta %>% filter(diagnosis == "COVID-19") %>% 
  filter(superinfection == "Superinfection")

#How many samples do we have of patients with "Other Pneumonia" that are younger than 50?
meta %>% filter(diagnosis == "Other Pneumonia", age < 50)

#How many patients do we have of patients with "Other Pneumonia" that are younger than 50?
meta %>% filter(diagnosis == "Other Pneumonia", age < 50) %>% 
  group_by(patient_id)

#What is the average "days from first intubation" for the Covid patients compared to the average "days from first intubation" for the other groups of diagnosis?

meta %>% 
  group_by(diagnosis) %>% 
  summarise(av_days_from_first_intu = mean(days_from_first_intubation))
  
 
```

## Visualization using ggplot2

[**ggplot2**](https://ggplot2.tidyverse.org) is a plotting package that allows us to plot a variety of easy, as well as complex plots. In general, ggplot2 builds graphics in a "layer-by-layer" fashion, by adding new elements step-wise. 

The basic syntax to build a ggplot figure, looks like the following: 

```{r, eval= FALSE}

ggplot(data = <DATA>, mapping = aes(<MAPPINGS>)) + <GEOM_FUNCTION>()

```

First of all, we have to specify the data frame we would like to plot in the **data** argument. In the **mapping** argument, we define the aesthetics of the plot: We select the variables we want to plot and how we want them to be plotted (e.g. [as x/y positions](https://r-graph-gallery.com/238-custom-layout-axis-ggplot2.html), size, shape, [color](https://r-graph-gallery.com/ggplot2-color.html)...). <br>
Last, we have to define the **`geom_`** (here is a [list](https://r-graph-gallery.com/ggplot2-package.html)). This sets the representation of the data in the plot (e.g. scatter plot, barplot, boxplot, ...). <br>

  + Look at here for some examples on how to build a [boxplot](https://r-graph-gallery.com/89-box-and-scatter-plot-with-ggplot2.html) or a [barplot](https://r-graph-gallery.com/48-grouped-barplot-with-ggplot2). 
  + You can also use this ![cheatsheet](./ggplot_cheatseet.png)
  + Or you can always ask google.

Before you start the next Hands-on session, let's try to create a very simple bar plot with one of the previously computed summary statistics in which we counted the number of patients per diagnosis.  

```{r, eval= TRUE}

#Counting the number of patients per diagnosis and store it in a summary table
no_of_patients_per_diagnosis <- meta %>% 
  group_by(diagnosis) %>% 
  dplyr::summarise(no_of_patients = n()) 

#Using ggplot to visualize the numer of patients per diagnosis in a barplot
ggplot(data = no_of_patients_per_diagnosis, aes(x = diagnosis, y = no_of_patients)) + geom_col() 

```

> **Hands-on:** 
> 
Let's try to reproduce some parts of the paper of Figure 1 to visualize the distribution of the cohort using ggplot2. 
>
* Have a look at Figure 1 (panel c and d) of the paper before starting this excercise. The link of the paper is provided at the beginning of the document. 
* Use a boxplot to visualize the distribution of age of the patients across the different groups of diagnosis (Fig. 1, panel c). It is also useful to not only plot the boxes, but also the data points itself. You can check on the internet how to plot the points on top of the boxplot and how to change the colors of the boxes. 
* Compute the **proportion** of sexes for the different diagnosis groups (Fig. 1, panel d) using the tidyverse functions `group_by()`{.R}, `summarise()`{.R} and `mutate()`{.R} visualize it in a stacked bar chart. If you are not happy with the colors, fontsizes or anything of the plot, you can always google.   

**Solutions**
```{r sol 4a, include = TRUE, eval = TRUE}

patient_age_plot <- ggplot(meta, aes(x = diagnosis, y = age, fill = diagnosis)) + 
  geom_boxplot() + 
  geom_jitter(size = 0.5) + 
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.9, hjust= 0.95)) +
  scale_fill_brewer(palette="Accent") + 
  ggtitle("Patient Age across the different Diagnosis") +
  theme(legend.position = "none") 
  
```

```{r sol 4b, include = TRUE, eval = TRUE}

sex_to_plot <- meta %>% 
  group_by(diagnosis, sex) %>% 
  dplyr::summarise(number_of_patients = n()) %>% 
  mutate(rel_no_of_pats = number_of_patients/sum(number_of_patients))

plot_sex <- ggplot(sex_to_plot, aes(x = diagnosis, y = rel_no_of_pats, fill = sex)) + 
  geom_bar(position="stack", stat = "identity") + 
  theme_classic() + 
  scale_fill_brewer(palette="Set2") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 0.9, hjust= 0.95)) + 
  ggtitle("Sex distribution across Diagnosis")
  
```

Your final plots should look somehow like these: 

```{r sol 4c, include = TRUE, eval = TRUE}

patient_age_plot + plot_sex
  
```

----------

# Exploring a Data set and cohort of single cell experiment
```{r loading packages 2, include=TRUE, eval=TRUE, results='hide'}
pkgs_needed = c("limma","muscat","purrr","ExperimentHub","scater")
letsinstall = setdiff(pkgs_needed, installed.packages()) 
if (length(letsinstall) > 0) {
  for (pkg in letsinstall) {
    BiocManager::install(pkg, dependencies = TRUE)
  }
}
library(limma)
library(muscat)
library(purrr)
library(ExperimentHub)
library(scater)
```

Until now we have analysed some data that was provided and was on our computer, you could have some data of your own like that.<br>
There are many example of data shared in Bioconductor, for example the one from the `muscat` data set (multi-sample multi-group scRNA-seq analysis tools). For now read through this practice and follow it step by step.

## Data descritpion
We will use a [*SingleCellExperiment*](https://bioconductor.org/packages/3.20/bioc/html/SingleCellExperiment.html) (SCE) dataset. In this dataset we have data collected from single cell RNA sequencing of peripheral blood mononuclear cell, that is cells of the immune system like T cells, B cells, NK cells and monocytes). The samples come from 8 patients with Lupus (an autoimmune disease), obtained before and after 6h-treatment with Interferon-β, IFNβ ([The Kang et al. (2018)](https://doi.org/10.1038/nbt.4042)). 

## Import data 
[The Kang et al. (2018)](https://doi.org/10.1038/nbt.4042) dataset has been made available through Bioconductor’s ExperimentHub and can be loaded into R as follows: we first initialize a Hub instance to search for and load available data with the ExperimentHub function, and store the complete list of records in the variable `eh`. Using query, we then retrieve any records that match our keyword(s) of interest, `Kang`, as well as their corresponding accession ID (EH1234).

```{r}
library(ExperimentHub)
eh <- ExperimentHub()
query(eh, "Kang")
```

We found 3 different records, the one we are interested in has accession ID "EH2259". We load the data of interest into R via `[[` and the corresponding accession ID. The dataset contains >35,000 genes and ~29,000 cells:

```{r}
sce <- eh[["EH2259"]]
```

Take a minute to look at the object we just loaded: <br>
```{r}
sce
```

+ it is a `singleCellExperiment` object, that is a matrix with some additional metadata information
+ in the matrix we have rows with gene's names and columns with cell's identifiers, how many precisely? (tip: which are the `dim`?)
+ in the `colData` there is some additional metadata information, you can take a look at it using the `colData()` function

```{r}
colData(sce)
```
you should see the row names (first column on the left) and 5 columns:

 + row names: cell barcode, one barcode identifies one cell
 + `ind`: is the individual identifier
 + `stim`: experimental condition - either treatment (`stim`) or control (`ctrl`) condition
 + `cluster`: cluster assigned based on transcription profiles
 + `cell`: cell type annotation
 + `multiplets`: if potentially the measurement is not from a single cell, it is indicated here. And we are going to remove it in some pre processing


## Preprocessing

The [*scater*](https://bioconductor.org/packages/3.20/scater) package (McCarthy et al. 2017) provides a variety of tools for preprocessing and quality control of single-cell transcriptomic data. For completeness, we will apply some minimal filtering steps to

+ remove undetected genes 
+ remove cells with very few or many detected genes 
+ remove very lowly expressed genes
+ compute normalized expression values for visualization

For more thorough preprocessing, we refer to the [Quality control with *scater*](https://bioconductor.org/packages/release/bioc/vignettes/scater/inst/doc/vignette-qc.html) vignette.
```{r}
# remove undetected genes, these are the genes for which we have no counts, 
# use the `rowSums` function to sum up the counts for one gene, if the total is more than 0, it returns TRUE, if it is less than 0 it returns FALSE. 
# We select only the rows that are TRUE.
sce <- sce[rowSums(counts(sce) > 0) > 0, ]
dim(sce)
```

We use `perCellQCMetrics` to compute various per-cell quality control metrics, and proceed with filtering cells and genes as noted above:
```{r}
library(scater)
qc <- perCellQCMetrics(sce)

# remove cells with few or many detected genes
ol <- isOutlier(metric = qc$detected, nmads = 2, log = TRUE)
# the cells are on the columns, and we keep out, using `!` the cells that are outlier and we selected above
sce <- sce[, !ol]
dim(sce)
```


```{r}
# remove lowly expressed genes
# we use rowSum again, this time to select only those that have a count more or equal to 10
sce <- sce[rowSums(counts(sce) > 1) >= 10, ]
dim(sce)
```

Finally, we use `logNormCounts` to calculate log2-transformed normalized expression values by dividing each count by its size factor, adding a pseudo-count of 1, and log-transforming11 Note that, in this workflow, expression values are used for visualization only, and that differential analyses are performed on pseudobulks (section 3.3) or the count data directly (section 3.4).
```{r}
# compute sum-factors & normalize
sce <- computeLibraryFactors(sce)
sce <- logNormCounts(sce)
```


