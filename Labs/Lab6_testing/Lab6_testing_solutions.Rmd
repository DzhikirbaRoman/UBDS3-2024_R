---
title: "Lab 6: Testing and RNA-Seq"
author: ""
date: ""
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Goal

In this lab, we will become familiar with count data in RNA-Seq high-throughput
sequencing. We will see how we can apply tools for hypothesis testing to data from RNA-Seq experiments. 
We will model counts data and evaluate model fits to detect and quantify systematic changes between 
conditions, compared to within-condition variability (which we consider noise).

## Load Packages

Install packages.

```{r warning=FALSE, message=FALSE, results='hide'}
pkgs_needed = c("dplyr","ggplot2", "DESeq2","pasilla","genefilter",
                "pheatmap","readr","tibble","apeglm")
BiocManager::install(setdiff(pkgs_needed, installed.packages()), dependencies = TRUE)
```

Load packages.

```{r warning=FALSE, message=FALSE, results='hide'}
library("dplyr")
library("ggplot2")
library("DESeq2")
library("pasilla")
library("genefilter")
library("pheatmap")
library("tibble")
```

## Example dataset: the pasilla data

The ``pasilla`` data are from an experiment on Drosophila melanogaster cell
cultures that investigated the **effect of RNAi knock-down of the splicing factor on the cells' transcriptome**.
The dataset is a collection of RNA-seq counts of different genes in different experimental
conditions, **treated** (siRNA against pasilla) or **untreated** (negative control).<br>
The experimental metadata of the `r ncol(counts)` samples in this dataset are provided in a spreadsheet-like 
table. Here, we use the function ``system.file`` to locate a file that is 
shipped together with the ``pasilla`` package. <br>
When you work with your own data, simply prepare and load the corresponding file.<br>
Let us load an example dataset. It resides in the experiment data package ``pasilla``. 

```{r loadpas, results="hide", error=FALSE}
# this point to a file name in your computer
fn = system.file("extdata", "pasilla_gene_counts.tsv",
                  package = "pasilla", mustWork = TRUE)
counts = as.matrix(read.csv(fn, sep = "\t", row.names = "gene_id"))
# "gene_id" is the first column in the file, that corresponds to the rownames

```
The data are stored as a rectangular table in a tab-delimited file, which
we've read into the matrix ``counts``.

Let's take a look at it:<br>
```{r counts}
dim(counts)
counts[ 2000+(0:3), ]
```

**Question 1**: what are the columns in the matrix?<br>

**Question 2**: how many genes are there in total?<br>

```{r solution1-2}
#TODO only in solutions
# 1. 
colnames(counts)
# there are 4 untreated and 3 treated samples
# 2. 
nrow(counts)
# 14599
# equivalent to do 
dim(counts)[1]
```

When loading data from a file, a good plausibility check is to print out some of 
the data, and maybe not only at the very beginning, but also at some random 
point in the middle, as we have done above. The table is a matrix of integer 
values: the value in the $i$th row and the $j$th column of the matrix indicates 
**how many reads have been mapped to gene $i$ in sample $j$**.  

**Question 3**: what is the read count for the 41st gene in the 3rd sample?<br>
**Question 4**: what is the name of the gene? And of the sample?<br>
```{r solution3-4}
#TODO only in solutions
# 3. 
counts[41,3]
# 4. 
rownames(counts)[41] # gene name
# "FBgn0000100"
colnames(counts)[3] # sample name
# "untreated3"
```

Now let's get the annotation file, that is again part of the ``pasilla`` package:<br>

```{r annotationFile}
annotationFile = system.file("extdata", "pasilla_sample_annotation.csv",
                             package = "pasilla", mustWork = TRUE)
pasillaSampleAnno = read.csv(annotationFile)
pasillaSampleAnno
```

As we see here, the overall dataset was produced in batches (indicated in the column "type" here)
the first one consisting of sequencing libraries that were subjected to **single-read** 
sequencing, the second batch consisting of libraries for which **paired-end**
sequencing was used.  

To have a general overview of our dataset, we can use the `str()` function (you can use it with any object type)
```{r str}
str(pasillaSampleAnno)
```
**Question 5**: how many columns contain numbers (integers) and how many are characters? <br>
**Answer 5**: "number.of.lanes" and "exon.counts" are "int" - intergers; all others are "chr" - characters

Let's convert the relevant columns of
``pasillaSampleAnno`` into factors, overriding the default level ordering 
(which is alphabetical) by one that makes more sense to us.

```{r factors}
pasillaSampleAnno = mutate(
  pasillaSampleAnno,
  condition = factor(condition, levels = c("untreated", "treated")),
  type      = factor(type, levels = c("single-read", "paired-end")))
```

**Question 6**: Are the "condition" and "type" column still characters?
```{r solution6}
str(pasillaSampleAnno)
```

Let's check if the design is balanced between the factor of interest, 
``condition``, and the nuisance factor ``type``. 
**Question 7**: How many sample are untreated and single-read, untreated and paired-end, treated and single-read, treated and paired-end?
Tip: Use the ``table`` function. If you don't know how it works, look it up doing ``help(table)``

```{r solution7}
table(pasillaSampleAnno[,c("condition","type")])
```
Now that we have an idea of how the data look like, let's prepare them for the analysis.<br>
We are going to use ``DESeq2``, that is a [Bioconductor package](https://bioconductor.org/packages/release/bioc/html/DESeq2.html) for differential gene expression analysis based on the negative binomial distribution. <br>
To use the functions from this package, first we need to create a ``DESeqDataSet`` from the matrix ``counts`` and the sample annotation dataframe ``pasillaSampleAnno``. To do so we can use the constructor function ``DESeqDataSetFromMatrix``.<br>
Look at this code now, do you know what each line does? Execute it step by step and look at the new objects created.<br>

**Question 8**: how is `pasillaSampleAnno[mt, ]` different from `pasillaSampleAnno`?<br>
**Answer 8**: `pasillaSampleAnno[mt, ]` is ordered so that the order of column `file` matches the order of the column names in `counts`

**Question 9**: what is the class of `pasilla` object? Is it a "SummarizedExperiment"<br>
**Answer 9**: it is a "DESeqDataSet", specific of the "DESeq2" dataset. Yes it is. <br>

You can always use `is()` function to check that your object is what you expect it to be. <br>

**Question 10**: for example are `pasillaSampleAnno` and `counts` data frames (data.frame) or matrices (matrix)?
```{r solution10}
is(pasillaSampleAnno, "data.frame")
is(counts, "matrix")
```

```{r DESeq2, message = FALSE, warning = FALSE}
mt = match(colnames(counts), sub("fb$", "", pasillaSampleAnno$file))

pasilla = DESeqDataSetFromMatrix(
  countData = counts,
  colData   = pasillaSampleAnno[mt, ],
  design    = ~ condition)

class(pasilla)
is(pasilla, "SummarizedExperiment")
```

Note how in the code above, we have to put in extra work to match the column 
names of the ``counts`` object with the ``file`` column of the 
``pasillaSampleAnno`` dataframe, in particular, we need to remove the ``fb`` 
that happens to be used in the ``file`` column for some reason. Such data 
wrangling is very common. One of the reasons for storing the data in a 
``DESeqDataSet`` object is that we then no longer have to worry about such 
things.


The ``SummarizedExperiment`` class --and therefore ``DESeqDataSet``-- also
contains facilities for storing annotation of the rows of the count matrix. 
For now, we are content with the gene identifiers from the row names of 
the ``counts`` table.


**Question 11**: When we constructed our `SummarizedExperiment` object, we 
also saved some column metadata which we had initially stored in 
`pasillaSampleAnno`. With which function can we extract this information again?
(Hint: type `?SummarizedExperiment`, look at the example at the end of the help. You can also print `pasilla` and see how it looks like)
```{r solution11}
colData(pasilla)
```



## The DESeq2 method

After these preparations, we are now ready to jump straight into differential 
expression analysis. A choice of standard analysis steps are wrapped into a
single function, ``DESeq``.

```{r deseq}
pasilla = DESeq(pasilla)
```

The DESeq function is simply a wrapper that calls, in order, the functions 
``estimateSizeFactors``, ``estimateDispersions`` (dispersion estimation) and 
``nbinomWaldTest`` (hypothesis tests for differential abundance). You can
always call these functions individually if you want to modify their behavior
or interject custom steps. Let us look at the results.

```{r theresults}
res = results(pasilla)
res[order(res$padj), ] %>% head
```
The first step after a differential expression analysis is visualization of the
results.


### Histogram of p-values

Now let's take a look at the p-value distribution:
```{r hist1, fig.width = 4.5, fig.height = 4.5}
ggplot(as(res, "data.frame"), aes(x = pvalue)) +
  geom_histogram(binwidth = 0.01, fill = "Royalblue", boundary = 0)
```

The distribution displays two main components: a uniform background with values 
between 0 and 1, and a peak of small p-values at the left.  

**Question 12**: which genes do you think correspond to differentially expressed genes? Why?<br>

**Answer 12**: The uniform background corresponds to the non-differentially expressed genes. Usually this 
is the majority of genes. The left hand peak corresponds to differentially 
bioexpressed genes.

The ratio of the level of the background to the height of the peak gives us 
a rough indication of the false discovery rate (FDR) that would be associated 
with calling the genes in the leftmost bin differentially expressed.

**Question 13**: What is the FDR (in %) for the leftmost bin (i.e. when
rejecting hypotheses smaller than 0.01)? The code snippet below might be a good 
starting point. Estimate the background level with the median bin count in the 
histogram object.

```{r hist2}
# Assuming p_values is your vector of p-values
pv_hist <- hist(res$pvalue, breaks=seq(0, 1, length=100), plot=F)

# Extract the counts from the histogram
pv_counts <- pv_hist$counts

# Estimate the background level with the median bin count
background <- median(pv_counts)

# Count for the leftmost bin (i.e., p-values < 0.01)
left_bin <- pv_counts[1]

# Calculate the False Discovery Rate (FDR) for the leftmost bin
FDR <- (left_bin / background) * 100

# Print the FDR
FDR

```

Recall from class the we can use `p.adjust` function to conduct multiple testing 
directly on the p-values (and we reject the adjusted p-values $\leq \alpha$). 
Let us quickly extract the p-values and remove the NAs:

```{r}
pvals <- na.omit(res$pvalue)
```

**Question 14**: How many p-values are <= 0.1?

**Question 15**: How many hypotheses do you reject with Benjamini-Hochberg 
at a FDR of 0.1?

**Question 16**: How many hypotheses do you reject with Bonferroni at a 
FWER of 0.1?

```{r solution14-16}
# 14.
sum(pvals <= 0.1)

# 15. 
pvals_FDR <- p.adjust(pvals, method = "BH")
sum(pvals_FDR <= 0.1)

# 16.
pvals_Bon <- p.adjust(pvals, method = "bonferroni")
sum(pvals_Bon <= 0.1)

```

You might notice that your answer to 15 is different than what the adjusted
p-values in `res$padj` might imply; the reason is that internally DESeq2 
uses a more advanced method to do the FDR correction compared to 
Benjamini-Hochberg (a simplified variant of IHW in which low counts genes get 
filtered out). 

We can use the p-value histogram plot for
diagnostic purposes. Let's look at a simulation to understand this point. 
First, we simulate four samples under the null hypothesis in which we state that 
the mean and the variance of the two conditions are the same; 
the alternative hypothesis state that mean and variance in the two conditions are different - 
the genes are differentially expressed.<br>
Then we apply the t-tests:

```{r uniform_hist}
set.seed(0xdada2)
# rnorm is a function that simulates a normal distribution, 
# sampling 10000 numbers, from a distribution of mean 0 and variance 0
# All 4 samples (2 Controls and 2 Treated) have the same mean
y = cbind(rnorm(10000, 0, 1),
          rnorm(10000, 0, 1),
          rnorm(10000, 0, 1),
          rnorm(10000, 0, 1))
library(genefilter)
pvalue = rowttests(y, factor(c("C","C","T","T")))$p.value
ggplot(tibble(pvalue), aes(x = pvalue)) +
  geom_histogram(binwidth = 0.01, fill = "Royalblue", boundary = 0)
```

Looks good. But now assume that two samples were processed on the same day 
separately from the others. That day, something happened and the means in both 
samples were shifted. In that case, the histogram is skewed to the right. 

**Question 17**: Now try to modify the code above:<br>

  a. by simulating two control samples with mean different from the two treated samples, how does the plot look like?<br>
  b. by shifting the mean of the second and fourth sample by two? What do you observe?

```{r solution17, fig.width = 4.5, fig.height = 4.5}
#a. 
set.seed(0xdada2)
y = cbind(rnorm(10000, 0, 1),
          rnorm(10000, 0, 1),
          rnorm(10000, 2, 1),
          rnorm(10000, 2, 1))
pvalue = rowttests(y, factor(c("C","C","T","T")))$p.value
ggplot(tibble(pvalue), aes(x = pvalue)) +
  geom_histogram(binwidth = 0.01, fill = "Royalblue", boundary = 0)

#b.
set.seed(0xdada2)
y = cbind(rnorm(10000, 0, 1),
          rnorm(10000, 2, 1),
          rnorm(10000, 0, 1),
          rnorm(10000, 2, 1))
pvalue = rowttests(y, factor(c("C","C","T","T")))$p.value
ggplot(tibble(pvalue), aes(x = pvalue)) +
  geom_histogram(binwidth = 0.01, fill = "Royalblue", boundary = 0)
```

One way to take such batch effects into account is by adding the batch factor 
(e.g. the run day) in our model. 

What can you do if you suspect there are ''hidden'' factors that affect your 
data, but they are not documented? (Sometimes, such unknown/undocumented 
covariates are also called batch effects.) There are methods that try to 
identify blocking factors in an unsupervised fashion, see e.\,g., 
[Leek and Storey 2007](http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0030161) 
or [Stegle et al 2010](http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1000770).

## Two-factor analysis of the pasilla data

Besides the treatment with siRNA, the ``pasilla`` data have another covariate,
``type``, which indicates the type of sequencing that was performed.
With a PCA (not shown here, but you can try it out!) we can see that the sequencing ``type``
has a considerable systematic effect on the data. 
Our basic analysis did not take this account, but we will do so now. 
This should help us get a more correct picture of which
differences in the data are attributable to the treatment, and which are
confounded --or masked-- by the sequencing type.

```{r replaceDesign}
pasillaTwoFactor = pasilla
# with design we are including the covariates in the formula...
design(pasillaTwoFactor) = formula(~ type + condition)
pasillaTwoFactor = DESeq(pasillaTwoFactor)
```

Of the two variables ``type`` and ``condition``, the one of primary interest
is the latter, and in ``DESeq2``, the convention is to put it at the end of the
formula. This convention has no effect on the model fitting, but it helps 
simplify some of the subsequent results reporting. Again, we access the results 
using the
``results`` function.

```{r multiResults}
res2 = results(pasillaTwoFactor)
head(res2, n = 3)
```

It is also possible to retrieve the $\log_2$ fold changes, p-values and adjusted
p-values associated with the ``type`` variable.  The function ``results`` takes an
argument ``contrast`` that lets users specify the name of the variable, the level
that corresponds to the numerator of the fold change and the level that corresponds
to the denominator of the fold change.

```{r multiTypeResults}
resType = results(pasillaTwoFactor, 
                  contrast = c("type", "single-read", "paired-end"))
head(resType, n = 3)
```

So what did we gain from this analysis that took into account ``type`` as a 
nuisance factor (sometimes also called, more politely, a ``blocking factor``), 
compared to the simple comparison between two groups? Let us plot the
p-values from both analyses against each other.

```{r scpres1res2,  warning = FALSE}
trsf = function(x) ifelse(is.na(x), 0, (-log10(x)) ^ (1/6))
ggplot(tibble(pOne = res$pvalue,
              pTwo = res2$pvalue),
    aes(x = trsf(pOne), y = trsf(pTwo))) +
    geom_hex(bins = 75) + coord_fixed() +
    xlab("Single factor analysis (condition)") +
    ylab("Two factor analysis (type + condition)") +
    geom_abline(col = "orange")
```

Comparison of p-values from the models with a single factor (condition) and with
two factors (type + condition). The axes correspond to 
$(-\log_{10}p)^{\frac{1}{6}}$, an arbitrarily chosen monotonically decreasing 
transformation that compresses the dynamic range of the p-values for the purpose 
of visualization. We can see a trend for the joint distribution to lie above the
bisector, indicating that the p-values in the two-factor analysis are generally 
smaller than those in the one-factor analysis.

As we can see, the p-values in the two-factor analysis are similar to those 
from the one-factor analysis, but are generally smaller. The more sophisticated 
analysis has led to an, albeit modest, increase in power. We can also see this 
by counting the number of genes that pass a certain significance threshold in 
each case:

```{r compareRes}
compareRes = table(
   `simple analysis` = res$padj < 0.1,
   `two factor` = res2$padj < 0.1 )
addmargins( compareRes )
```

The two-factor analysis found `r sum(compareRes[,2])` genes differentially 
expressed at an FDR threshold of 10\%, while the one-factor analysis found 
`r sum(compareRes[2,])`. The two-factor analysis has increased detection power. 
In general, the gain can be even much larger, or also smaller, depending on the 
data. The proper choice of the model requires informed adaptation to the
experimental design and data quality.

 Why do we detect fewer significant genes when we do not take into account the
``type`` variable?  More generally, what does this mean about the benefit of 
taking into account (or not) blocking factors?

Without modeling the blocking factor, the variability in the data that is due 
to it has to be absorbed by the $\varepsilon$s. This means that they are 
generally larger than in the model with the blocking factor. The higher level
of noise leads to higher uncertainty in the $\beta$-estimates.  On the other 
hand, the model with the blocking factor has more parameters that need to be 
estimated. In statistical parlance, the fit has fewer ``degrees of freedom''.  
Both of these effects are counteracting, and which of them prevails, and which 
of the modeling choices yields more or fewer significant results depends 
on the data.
  
As a note of caution: The two p-values calculated above (one with ~condition
and one with ~type+condition) correspond to different null hypotheses. This 
can be a problem when the blocking factor and condition are correlated.